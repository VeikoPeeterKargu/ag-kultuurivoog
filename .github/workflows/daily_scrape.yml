name: Daily Scrape

on:
  schedule:
    # Cron on UTC. 02:00 UTC = 04:00 Tallinn (talvel).
    - cron: "0 2 * * *"
  workflow_dispatch: {}

concurrency:
  group: scrape-job
  cancel-in-progress: false

jobs:
  scrape_and_update:
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Sanity check secrets
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
        run: |
          if [ -z "$DATABASE_URL" ]; then
            echo "ERROR: DATABASE_URL secret missing"
            exit 1
          fi
          echo "DATABASE_URL_PRESENT: true"

      - name: Init DB schema & views
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
        run: |
          echo "DB_INIT_START: true"
          python db_init.py
          echo "DB_INIT_DONE: true"

      - name: Run teater.ee scraper
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
        run: |
          echo "TEATER_RUN_START: true"
          python scrape_teater_ee.py
          echo "TEATER_RUN_DONE: true"

      - name: Run concert.ee scraper (non-fatal)
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
        continue-on-error: true
        run: |
          echo "CONCERT_RUN_START: true"
          python scrape_concert_ee.py
          echo "CONCERT_RUN_DONE: true"

      - name: Cleanup and ensure views
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
        run: |
          echo "CLEANUP_START: true"
          python cleanup_non_events.py
          echo "CLEANUP_DONE: true"
